#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–çš„RAGè¿è¡Œè„šæœ¬ - æœ¬åœ°CPUç‰ˆæœ¬
Simplified RAG runner - Local CPU Version
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ å…±äº«æ•°æ®è·¯å¾„
SHARED_DATA_PATH = Path(__file__).parent.parent / "shared_data"

# å¯¼å…¥å¿…è¦çš„åº“
from llama_cpp import Llama
from typing import List
from googlesearch import search as _search
from bs4 import BeautifulSoup
from charset_normalizer import detect
from requests_html import AsyncHTMLSession
import urllib3
urllib3.disable_warnings()

print("ğŸš€ æ­£åœ¨åŠ è½½æ¨¡å‹...")

# åŠ è½½æ¨¡å‹åˆ°CPU - ä½¿ç”¨å…±äº«æ•°æ®è·¯å¾„
model_path = SHARED_DATA_PATH / "Meta-Llama-3.1-8B-Instruct-Q8_0.gguf"
llama3 = Llama(
    str(model_path),
    verbose=False,
    n_gpu_layers=0,  # ä½¿ç”¨CPU
    n_ctx=16384,     # ä¸Šä¸‹æ–‡çª—å£å¤§å°
    n_threads=4,     # CPUçº¿ç¨‹æ•°ï¼Œå¯ä»¥æ ¹æ®ä½ çš„CPUè°ƒæ•´
)

def generate_response(_model: Llama, _messages: str) -> str:
    '''
    è¿™ä¸ªå‡½æ•°å°†ä½¿ç”¨ç»™å®šçš„æ¶ˆæ¯å¯¹æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚
    '''
    _output = _model.create_chat_completion(
        _messages,
        stop=["<|eot_id|>", "<|end_of_text|>"],
        max_tokens=512,
        temperature=0,
        repeat_penalty=2.0,
    )["choices"][0]["message"]["content"]
    return _output

# æœç´¢å·¥å…·
async def worker(s:AsyncHTMLSession, url:str):
    """å¼‚æ­¥è·å–ç½‘é¡µå†…å®¹"""
    try:
        header_response = await asyncio.wait_for(s.head(url, verify=False), timeout=10)
        if 'text/html' not in header_response.headers.get('Content-Type', ''):
            return None
        r = await asyncio.wait_for(s.get(url, verify=False), timeout=10)
        return r.text
    except:
        return None

async def get_htmls(urls):
    """å¼‚æ­¥è·å–å¤šä¸ªç½‘é¡µçš„HTMLå†…å®¹"""
    session = AsyncHTMLSession()
    tasks = (worker(session, url) for url in urls)
    return await asyncio.gather(*tasks)

async def search(keyword: str, n_results: int=3) -> List[str]:
    '''
    æœç´¢å…³é”®è¯å¹¶è¿”å›ç½‘é¡µæ–‡æœ¬å†…å®¹
    '''
    keyword = keyword[:100]
    results = list(_search(keyword, n_results * 2, lang="zh", unique=True))
    results = await get_htmls(results)
    results = [x for x in results if x is not None]
    results = [BeautifulSoup(x, 'html.parser') for x in results]
    results = [''.join(x.get_text().split()) for x in results if detect(x.encode()).get('encoding') == 'utf-8']
    return results[:n_results]

# Agentç±»
class LLMAgent():
    def __init__(self, role_description: str, task_description: str, llm:str="bartowski/Meta-Llama-3.1-8B-Instruct-GGUF"):
        self.role_description = role_description
        self.task_description = task_description
        self.llm = llm
    
    def inference(self, message:str) -> str:
        if self.llm == 'bartowski/Meta-Llama-3.1-8B-Instruct-GGUF':
            messages = [
                {"role": "system", "content": f"{self.role_description}"},
                {"role": "user", "content": f"{self.task_description}\n{message}"},
            ]
            return generate_response(llama3, messages)
        else:
            return ""

# å®šä¹‰å„ä¸ªä»£ç†
question_extraction_agent = LLMAgent(
    role_description="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®é¢˜åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»å¤æ‚é—®é¢˜ä¸­æå–æ ¸å¿ƒå†…å®¹ã€‚",
    task_description="è¯·åˆ†æä»¥ä¸‹é—®é¢˜ï¼Œæå–æ ¸å¿ƒé—®é¢˜å†…å®¹ï¼Œä¿æŒé—®é¢˜çš„æ ¸å¿ƒå«ä¹‰ã€‚å¦‚æœé—®é¢˜å·²ç»ç®€æ´æ˜äº†ï¼Œè¯·ç›´æ¥è¿”å›åŸé—®é¢˜ã€‚",
)

keyword_extraction_agent = LLMAgent(
    role_description="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å…³é”®è¯æå–ä¸“å®¶ï¼Œæ“…é•¿ä»é—®é¢˜ä¸­è¯†åˆ«æœ€é‡è¦çš„æœç´¢å…³é”®è¯ã€‚",
    task_description="è¯·ä»ä»¥ä¸‹é—®é¢˜ä¸­æå–3-5ä¸ªæœ€é‡è¦çš„æœç´¢å…³é”®è¯ï¼Œç”¨ç©ºæ ¼åˆ†éš”ã€‚å…³é”®è¯åº”è¯¥èƒ½å‡†ç¡®åæ˜ é—®é¢˜çš„æ ¸å¿ƒå†…å®¹ï¼Œä¾¿äºç½‘ç»œæœç´¢æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚",
)

qa_agent = LLMAgent(
    role_description="ä½ æ˜¯ LLaMA-3.1-8Bï¼Œæ˜¯ç”¨ä¾†å›ç­”å•é¡Œçš„ AIã€‚",
    task_description="è¯·æ ¹æ®ä½ çš„çŸ¥è¯†åº“å’Œæä¾›çš„ç›¸å…³ä¿¡æ¯ï¼Œå…¨é¢ã€å‡†ç¡®åœ°å›ç­”ä»¥ä¸‹é—®é¢˜ã€‚å¦‚æœç›¸å…³ä¿¡æ¯ä¸é—®é¢˜ç›¸å…³ï¼Œè¯·å……åˆ†åˆ©ç”¨ï¼›å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·åŸºäºä½ çš„çŸ¥è¯†è¿›è¡Œå›ç­”ã€‚ç›´æ¥è¾“å‡ºæœ€ç»ˆç­”æ¡ˆçš„å†…å®¹ã€‚ä¸ç”¨è¾“å‡ºä¸­é—´çš„åˆ†æè¿‡ç¨‹å’Œä¸ç›¸å…³çš„ä¿¡æ¯ã€‚",
)

answer_verification_agent = LLMAgent(
    role_description="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç­”æ¡ˆæ£€æŸ¥ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¯¹äºè¢«æå‡ºçš„é—®é¢˜ï¼Œç¡®ä¿AIç”Ÿæˆçš„ç­”æ¡ˆæ˜¯å‡†ç¡®çš„,ç¬¦åˆé€»è¾‘çš„ã€‚",
    task_description="è¯·æ£€æŸ¥æ ¸å¯¹ç­”æ¡ˆæ˜¯å¦æ­£ç¡®çš„ç¬¦åˆé€»è¾‘çš„å›ç­”äº†è¢«æå‡ºçš„é—®é¢˜ï¼Œå¦‚æœæœ‰é”™è¯¯è¯·ä¿®æ­£ç­”æ¡ˆï¼Œå¹¶ç›´æ¥è¾“å‡ºæœ€ç»ˆä¿®æ­£ç­”æ¡ˆçš„å†…å®¹ï¼Œå¦‚æœæ²¡æœ‰é”™è¯¯ï¼Œç›´æ¥è¾“å‡ºæœ€ç»ˆç­”æ¡ˆçš„å†…å®¹ã€‚ä¸ç”¨è¾“å‡ºä¸­é—´çš„åˆ†æè¿‡ç¨‹å’Œä¸ç›¸å…³çš„ä¿¡æ¯ã€‚"
)

# RAGç®¡é“
async def pipeline(question: str) -> str:
    """
    4-Agentåä½œçš„RAGç®¡é“
    """
    try:
        # Step 1: é—®é¢˜æ¸…ç†
        cleaned_question = question_extraction_agent.inference(question)
        print(f"æ¸…ç†åé—®é¢˜: {cleaned_question}")
        
        # Step 2: å…³é”®è¯æå–
        keywords = keyword_extraction_agent.inference(cleaned_question)
        print(f"æå–å…³é”®è¯: {keywords}")

        # Step 3: ç½‘ç»œæœç´¢
        try:
            search_strategies = [
                f'"{keywords}"',
                f'"{cleaned_question}"',
                f'"{keywords}" æ ¡æ­Œ',
                keywords,
            ]
            
            search_results = []
            for strategy in search_strategies:
                try:
                    results = await search(strategy, n_results=2)
                    search_results.extend(results)
                    if len(search_results) >= 3:
                        break
                except Exception as e:
                    continue
            
            unique_results = list(dict.fromkeys(search_results))
            truncated_search_results = [result[:2000] for result in unique_results[:3]]
            
            if truncated_search_results:
                formatted_results = []
                for i, result in enumerate(truncated_search_results, 1):
                    cleaned_result = result.strip()
                    
                    if cleaned_result and len(cleaned_result) > 50:
                        import re
                        cleaned_result = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', cleaned_result)
                        cleaned_result = re.sub(r'\s+', ' ', cleaned_result)
                        cleaned_result = re.sub(r'<[^>]+>', '', cleaned_result)
                        cleaned_result = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', cleaned_result)
                        
                        if cleaned_result.strip() and len(cleaned_result.strip()) > 30:
                            formatted_results.append(f"å‚è€ƒä¿¡æ¯{i}: {cleaned_result.strip()}")
                
                if formatted_results:
                    enhanced_question = f"é—®é¢˜ï¼š{cleaned_question}\n\nå‚è€ƒä¿¡æ¯ï¼š\n" + "\n\n".join(formatted_results)
                else:
                    enhanced_question = cleaned_question
            else:
                enhanced_question = cleaned_question
        except Exception as e:
            print(f"æœç´¢å¤±è´¥: {e}")
            enhanced_question = cleaned_question
        
        if "å‚è€ƒä¿¡æ¯" not in enhanced_question:
            print("æœªæ‰¾åˆ°ç›¸å…³å‚è€ƒä¿¡æ¯ï¼Œä½¿ç”¨LLMçŸ¥è¯†åº“å›ç­”")
            enhanced_question = f"é—®é¢˜ï¼š{cleaned_question}\n\nè¯·åŸºäºä½ çš„çŸ¥è¯†åº“å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œä¸éœ€è¦å¤–éƒ¨å‚è€ƒä¿¡æ¯ã€‚"

        # Step 4: ç”Ÿæˆåˆæ­¥ç­”æ¡ˆ
        initial_answer = qa_agent.inference(enhanced_question)
        print(f"åˆæ­¥ç­”æ¡ˆ: {initial_answer}")

        # Step 5: ç­”æ¡ˆè´¨é‡æ£€æŸ¥
        final_answer = answer_verification_agent.inference(initial_answer)
        print(f"æœ€ç»ˆç­”æ¡ˆ: {final_answer}")

        return final_answer
        
    except Exception as e:
        print(f"ç®¡é“æ‰§è¡Œå¤±è´¥: {e}")
        return qa_agent.inference(question)

# æµ‹è¯•å‡½æ•°
async def test_single_question():
    """æµ‹è¯•å•ä¸ªé—®é¢˜"""
    print("ğŸ§ª æµ‹è¯•å•ä¸ªé—®é¢˜...")
    print("=" * 50)
    
    test_question = "å…‰è¯åœ‹å°çš„æ ¡æ­Œæ˜¯ã€è™å±±é›„é¢¨é£›æšã€ã€‚"
    print(f"æµ‹è¯•é—®é¢˜: {test_question}")
    print("-" * 30)
    
    try:
        answer = await pipeline(test_question)
        print(f"ç”Ÿæˆçš„ç­”æ¡ˆ: {answer}")
        print(f"ç­”æ¡ˆé•¿åº¦: {len(answer)} å­—ç¬¦")
        
        if answer and len(answer.strip()) > 0:
            print("âœ… æµ‹è¯•æˆåŠŸï¼pipelineå‡½æ•°æ­£å¸¸å·¥ä½œ")
        else:
            print("âŒ æµ‹è¯•å¤±è´¥ï¼pipelineå‡½æ•°æ²¡æœ‰ç”Ÿæˆç­”æ¡ˆ")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥ï¼é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    print("=" * 50)

# ä¸»å‡½æ•°
async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¼€å§‹å¤„ç†é—®é¢˜...")
    
    STUDENT_ID = "local_cpu_test"
    
    # å¤„ç†public.txtä¸­çš„é—®é¢˜ - ä½¿ç”¨å…±äº«æ•°æ®è·¯å¾„
    public_path = SHARED_DATA_PATH / "public.txt"
    if public_path.exists():
        print("ğŸ“– å¤„ç†public.txtä¸­çš„é—®é¢˜...")
        with open(public_path, 'r', encoding='utf-8') as input_f:
            questions = input_f.readlines()
            questions = [l.strip().split(',')[0] for l in questions]
            
            for id, question in enumerate(questions, 1):
                output_path = Path(f"./{STUDENT_ID}_{id}.txt")
                if output_path.exists():
                    print(f"è·³è¿‡é—®é¢˜ {id} (å·²å­˜åœ¨)")
                    continue
                
                print(f"\nå¤„ç†é—®é¢˜ {id}: {question}")
                answer = await pipeline(question)
                answer = answer.replace('\n',' ')
                print(f"ç­”æ¡ˆ: {answer}")
                
                with open(output_path, 'w', encoding='utf-8') as output_f:
                    print(answer, file=output_f)
    
    # å¤„ç†private.txtä¸­çš„é—®é¢˜ - ä½¿ç”¨å…±äº«æ•°æ®è·¯å¾„
    private_path = SHARED_DATA_PATH / "private.txt"
    if private_path.exists():
        print("ğŸ“– å¤„ç†private.txtä¸­çš„é—®é¢˜...")
        with open(private_path, 'r', encoding='utf-8') as input_f:
            questions = input_f.readlines()
            
            for id, question in enumerate(questions, 31):
                output_path = Path(f"./{STUDENT_ID}_{id}.txt")
                if output_path.exists():
                    print(f"è·³è¿‡é—®é¢˜ {id} (å·²å­˜åœ¨)")
                    continue
                
                print(f"\nå¤„ç†é—®é¢˜ {id}: {question}")
                answer = await pipeline(question)
                answer = answer.replace('\n',' ')
                print(f"ç­”æ¡ˆ: {answer}")
                
                with open(output_path, 'w', encoding='utf-8') as output_f:
                    print(answer, file=output_f)
    
    # åˆå¹¶ç»“æœåˆ°ä¸€ä¸ªæ–‡ä»¶
    print("ğŸ“ åˆå¹¶ç»“æœ...")
    with open(f'./{STUDENT_ID}.txt', 'w', encoding='utf-8') as output_f:
        for id in range(1, 91):
            file_path = Path(f'./{STUDENT_ID}_{id}.txt')
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as input_f:
                    answer = input_f.readline().strip()
                    print(answer, file=output_f)
            else:
                print("", file=output_f)
    
    print("âœ… å¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨æœ¬åœ°CPUç‰ˆæœ¬çš„RAGç³»ç»Ÿ...")
    
    # é€‰æ‹©è¿è¡Œæ¨¡å¼
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        asyncio.run(test_single_question())
    else:
        asyncio.run(main()) 